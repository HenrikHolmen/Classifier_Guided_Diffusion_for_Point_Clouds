[2024-06-20 19:27:17,075::test::INFO] [ARGS::ckpt] '/work3/s210659/baseline_gen48h/GEN_2024_06_16__15_49_38_Config1_1040k/ckpt_0.000000_520000.pt'
[2024-06-20 19:27:17,075::test::INFO] [ARGS::categories] ['airplane']
[2024-06-20 19:27:17,076::test::INFO] [ARGS::save_dir] '/work3/s210659/baseline_gen_test_results'
[2024-06-20 19:27:17,076::test::INFO] [ARGS::device] 'cuda'
[2024-06-20 19:27:17,077::test::INFO] [ARGS::dataset_path] '/work3/s210659/data/shapenet.hdf5'
[2024-06-20 19:27:17,077::test::INFO] [ARGS::batch_size] 128
[2024-06-20 19:27:17,077::test::INFO] [ARGS::sample_num_points] 2048
[2024-06-20 19:27:17,078::test::INFO] [ARGS::normalize] 'shape_bbox'
[2024-06-20 19:27:17,078::test::INFO] [ARGS::seed] 9988
[2024-06-20 19:27:20,548::test::INFO] Loading datasets...
[2024-06-20 19:27:20,751::test::INFO] Loading model...
[2024-06-20 19:27:20,824::test::INFO] FlowVAE(
  (encoder): PointNetEncoder(
    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc1_m): Linear(in_features=512, out_features=256, bias=True)
    (fc2_m): Linear(in_features=256, out_features=128, bias=True)
    (fc3_m): Linear(in_features=128, out_features=256, bias=True)
    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc1_v): Linear(in_features=512, out_features=256, bias=True)
    (fc2_v): Linear(in_features=256, out_features=128, bias=True)
    (fc3_v): Linear(in_features=128, out_features=256, bias=True)
    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (flow): SequentialFlow(
    (chain): ModuleList(
      (0): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (1): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (2): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (3): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (4): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (5): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (6): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (7): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (8): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (9): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (10): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (11): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (12): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (13): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (diffusion): DiffusionPoint(
    (net): PointwiseNet(
      (layers): ModuleList(
        (0): ConcatSquashLinear(
          (_layer): Linear(in_features=3, out_features=128, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)
        )
        (1): ConcatSquashLinear(
          (_layer): Linear(in_features=128, out_features=256, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)
        )
        (2): ConcatSquashLinear(
          (_layer): Linear(in_features=256, out_features=512, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)
        )
        (3): ConcatSquashLinear(
          (_layer): Linear(in_features=512, out_features=256, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)
        )
        (4): ConcatSquashLinear(
          (_layer): Linear(in_features=256, out_features=128, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)
        )
        (5): ConcatSquashLinear(
          (_layer): Linear(in_features=128, out_features=3, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)
        )
      )
    )
    (var_sched): VarianceSchedule()
  )
)
[2024-06-20 19:27:57,404::test::INFO] Normalization mode: shape_bbox
[2024-06-20 19:27:57,460::test::INFO] Saving point clouds...
[2024-06-20 19:38:33,978::test::INFO] lgan_mmd-CD: 0.003372473642
[2024-06-20 19:38:33,979::test::INFO] lgan_cov-CD: 0.425041198730
[2024-06-20 19:38:33,980::test::INFO] lgan_mmd_smp-CD: 0.002811017446
[2024-06-20 19:38:33,980::test::INFO] lgan_mmd-EMD: 0.028653729707
[2024-06-20 19:38:33,980::test::INFO] lgan_cov-EMD: 0.308072477579
[2024-06-20 19:38:33,981::test::INFO] lgan_mmd_smp-EMD: 0.025092337281
[2024-06-20 19:38:33,981::test::INFO] 1-NN-CD-acc_t: 0.558484375477
[2024-06-20 19:38:33,982::test::INFO] 1-NN-CD-acc_f: 0.942339360714
[2024-06-20 19:38:33,982::test::INFO] 1-NN-CD-acc: 0.750411868095
[2024-06-20 19:38:33,982::test::INFO] 1-NN-EMD-acc_t: 0.667215824127
[2024-06-20 19:38:33,983::test::INFO] 1-NN-EMD-acc_f: 0.672158181667
[2024-06-20 19:38:33,983::test::INFO] 1-NN-EMD-acc: 0.669686973095
[2024-06-20 19:38:33,984::test::INFO] jsd: 0.017178063580
