[2024-06-20 18:19:23,101::test::INFO] [ARGS::ckpt] '/work3/s210659/baseline_gen48h/GEN_2024_06_14__13_10_35_Baseline_778k/ckpt_0.000000_270000.pt'
[2024-06-20 18:19:23,102::test::INFO] [ARGS::categories] ['airplane']
[2024-06-20 18:19:23,103::test::INFO] [ARGS::save_dir] '/work3/s210659/baseline_gen_test_results'
[2024-06-20 18:19:23,103::test::INFO] [ARGS::device] 'cuda'
[2024-06-20 18:19:23,103::test::INFO] [ARGS::dataset_path] '/work3/s210659/data/shapenet.hdf5'
[2024-06-20 18:19:23,104::test::INFO] [ARGS::batch_size] 128
[2024-06-20 18:19:23,104::test::INFO] [ARGS::sample_num_points] 2048
[2024-06-20 18:19:23,104::test::INFO] [ARGS::normalize] 'shape_bbox'
[2024-06-20 18:19:23,105::test::INFO] [ARGS::seed] 9988
[2024-06-20 18:19:42,083::test::INFO] Loading datasets...
[2024-06-20 18:19:42,442::test::INFO] Loading model...
[2024-06-20 18:19:42,610::test::INFO] FlowVAE(
  (encoder): PointNetEncoder(
    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc1_m): Linear(in_features=512, out_features=256, bias=True)
    (fc2_m): Linear(in_features=256, out_features=128, bias=True)
    (fc3_m): Linear(in_features=128, out_features=256, bias=True)
    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc1_v): Linear(in_features=512, out_features=256, bias=True)
    (fc2_v): Linear(in_features=256, out_features=128, bias=True)
    (fc3_v): Linear(in_features=128, out_features=256, bias=True)
    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (flow): SequentialFlow(
    (chain): ModuleList(
      (0): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (1): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (2): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (3): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (4): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (5): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (6): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (7): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (8): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (9): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (10): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (11): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (12): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (13): CouplingLayer(
        (net_s_t): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (diffusion): DiffusionPoint(
    (net): PointwiseNet(
      (layers): ModuleList(
        (0): ConcatSquashLinear(
          (_layer): Linear(in_features=3, out_features=128, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)
        )
        (1): ConcatSquashLinear(
          (_layer): Linear(in_features=128, out_features=256, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)
        )
        (2): ConcatSquashLinear(
          (_layer): Linear(in_features=256, out_features=512, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)
        )
        (3): ConcatSquashLinear(
          (_layer): Linear(in_features=512, out_features=256, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)
        )
        (4): ConcatSquashLinear(
          (_layer): Linear(in_features=256, out_features=128, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)
        )
        (5): ConcatSquashLinear(
          (_layer): Linear(in_features=128, out_features=3, bias=True)
          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)
          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)
        )
      )
    )
    (var_sched): VarianceSchedule()
  )
)
[2024-06-20 18:20:14,691::test::INFO] Normalization mode: shape_bbox
[2024-06-20 18:20:14,746::test::INFO] Saving point clouds...
[2024-06-20 18:30:50,290::test::INFO] lgan_mmd-CD: 0.003372623585
[2024-06-20 18:30:50,291::test::INFO] lgan_cov-CD: 0.434925854206
[2024-06-20 18:30:50,292::test::INFO] lgan_mmd_smp-CD: 0.002919407096
[2024-06-20 18:30:50,292::test::INFO] lgan_mmd-EMD: 0.028280505911
[2024-06-20 18:30:50,292::test::INFO] lgan_cov-EMD: 0.306425035000
[2024-06-20 18:30:50,293::test::INFO] lgan_mmd_smp-EMD: 0.025330862030
[2024-06-20 18:30:50,293::test::INFO] 1-NN-CD-acc_t: 0.571663916111
[2024-06-20 18:30:50,294::test::INFO] 1-NN-CD-acc_f: 0.922569990158
[2024-06-20 18:30:50,294::test::INFO] 1-NN-CD-acc: 0.747116923332
[2024-06-20 18:30:50,294::test::INFO] 1-NN-EMD-acc_t: 0.667215824127
[2024-06-20 18:30:50,294::test::INFO] 1-NN-EMD-acc_f: 0.632619440556
[2024-06-20 18:30:50,295::test::INFO] 1-NN-EMD-acc: 0.649917602539
[2024-06-20 18:30:50,295::test::INFO] jsd: 0.014986046792
